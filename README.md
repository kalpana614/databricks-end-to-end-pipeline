# Databricks End-to-End Pipeline (Medallion Architecture)

This project demonstrates a complete end-to-end data pipeline using **Databricks** and the **Medallion Architecture** (Bronze â†’ Silver â†’ Gold).

Key features of the pipeline:
- ğŸ” **Streaming ingestion** using **Databricks Autoloader**
- ğŸ§ª **Schema evolution** and rescue mode handling
- ğŸ§± **Bronze layer** for raw data ingestion
- ğŸ§¼ **Silver layer** built using **LakeFlow (Delta Live Tables)** for cleansing, CDC, and enrichment
- ğŸ§  **Data quality rules** and expectations with `@dlt.expect_all`
- ğŸ” **CDC handling** with `create_auto_cdc_flow()` (SCD Type 1)
- ğŸ“Š **Business-ready joins** and transformations in the Silver layer
- ğŸ“¦ (Optional) **Gold layer** for aggregations and reporting

This pipeline processes streaming datasets like **bookings, flights, passengers, and airports**, and transforms them into reliable, structured data ready for analytics.

ğŸ“Œ Technologies used:
- Databricks Lakehouse Platform
- PySpark
- Delta Lake
- Autoloader
- LakeFlow / Delta Live Tables (DLT)
- Structured Streaming

---

Feel free to fork, explore, or suggest improvements!
